version: v1
name: wf-ott-contract-02
type: workflow
tags:
  - contract
  - ott
description: The job performs metrics calculations and checks on contract data
workflow:
  title: Metrics and checks
  dag:
    - name: ott-contract-quality
      title: Metrics and checks
      description: The job performs metrics calculations and checks on contract data
      spec:
        stack: flare:3.0
        compute: runnable-default
        tags:
          - contract
          - ott
        title: Metrics and checks
        description: The job performs metrics calculations and checks on contract data
        flare:
          job:
            explain: true
            logLevel: INFO
            inputs:
              - name: ott_contract
                dataset: dataos://icebase:telco_ott/ott_contract
                format: iceberg
            assertions: 

#Verify whether the value of Contract ID is Unique in database
              - sql: |
                    SELECT
                      count(contract_id) count_contract_id
                    FROM
                      ott_contract
                    GROUP BY
                      contract_id
                test: 
                  - count_contract_id == 1

  #Verify whether the value of the Contract Effective Date is not greater than Contract End date
              - sql: |
                    SELECT
                      CASE
                      WHEN contract_effective_date IS NULL THEN 0
                      ELSE 1
                      END contract_effective_date
                      FROM
                        ott_contract
                      WHERE
                        contract_effective_date < contract_end_date
                        GROUP BY
                        1
                        ORDER BY
                        1
                tests: 
                  - contract_effective_date == 1

          sparkConf:
            - spark.serializer: org.apache.spark.serializer.KryoSerializer
            - spark.sql.shuffle.partitions: "10"
            - spark.memory.storageFraction: "0.1"
            - spark.memory.fraction: "0.1"
            - spark.shuffle.memoryFraction: "0.2"